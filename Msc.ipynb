{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "df = pd.read_csv('mtsamples.csv')\n",
        "df = df[['medical_specialty', 'transcription']].dropna()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# Count occurrences of each category\n",
        "category_counts = df['medical_specialty'].value_counts()\n",
        "valid_categories = category_counts[category_counts > 300].index\n",
        "df = df[df['medical_specialty'].isin(valid_categories)]\n",
        "\n",
        "# Print the valid categories\n",
        "print(\"Valid categories with more than 300 occurrences:\")\n",
        "print(valid_categories)\n",
        "# Tokenization function\n",
        "def preprocess_text(text):\n",
        "    return tokenizer(text, padding='max_length', truncation=True, return_tensors='pt', max_length=128)\n",
        "\n",
        "df['transcription'] = df['transcription'].apply(preprocess_text)\n",
        "df['input_ids'] = df['transcription'].apply(lambda x: x['input_ids'][0])\n",
        "df['attention_mask'] = df['transcription'].apply(lambda x: x['attention_mask'][0])\n",
        "\n",
        "# Convert to tensors\n",
        "X = torch.stack(df['input_ids'].tolist())\n",
        "attention_masks = torch.stack(df['attention_mask'].tolist())\n",
        "label_encoder = LabelEncoder()\n",
        "y = torch.tensor(label_encoder.fit_transform(df['medical_specialty']))\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test, train_masks, test_masks = train_test_split(\n",
        "    X, y, attention_masks, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create DataLoaders for BERT and LSTM\n",
        "train_dataset = TensorDataset(X_train, train_masks, y_train)\n",
        "test_dataset = TensorDataset(X_test, test_masks, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Create DataLoaders for CNN\n",
        "train_dataset_cnn = TensorDataset(X_train, y_train)\n",
        "test_dataset_cnn = TensorDataset(X_test, y_test)\n",
        "train_loader_cnn = DataLoader(train_dataset_cnn, batch_size=8, shuffle=True)\n",
        "test_loader_cnn = DataLoader(test_dataset_cnn, batch_size=8, shuffle=False)\n",
        "\n",
        "# Define BERT model\n",
        "class BERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.fc = nn.Linear(768, len(valid_categories))\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        outputs = self.bert(ids, attention_mask=mask, return_dict=False)\n",
        "        last_hidden_state = outputs[0]\n",
        "        pooled_output = last_hidden_state[:, 0, :]\n",
        "        return self.fc(pooled_output)\n",
        "\n",
        "# Define CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(30522, 128)\n",
        "        self.conv1 = nn.Conv1d(128, 64, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(64, 32, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.fc = nn.Linear(32 * 64, len(valid_categories))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        return self.fc(x)\n",
        "\n",
        "# Define LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(128, 128, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(128 * 2, len(valid_categories))\n",
        "\n",
        "    def forward(self, ids, masks):\n",
        "        lstm_output, _ = self.lstm(ids.float())\n",
        "        return self.fc(lstm_output[:, -1, :]) if lstm_output.dim() == 3 else self.fc(lstm_output)\n",
        "\n",
        "# Initialize models\n",
        "model_bert = BERTModel().to(device)\n",
        "model_cnn = CNNModel().to(device)\n",
        "model_lstm = LSTMModel().to(device)\n",
        "\n",
        "optimizer_bert = optim.Adam(model_bert.parameters(), lr=2e-5)\n",
        "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=1e-3)\n",
        "optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training function for BERT and LSTM models\n",
        "def train_model(model, optimizer, train_loader, model_name, epochs=1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for epoch in range(epochs):\n",
        "        for ids, masks, targets in train_loader:\n",
        "            ids, masks, targets = ids.to(device), masks.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(ids, masks)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        average_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}, {model_name} trained with average loss: {average_loss:.4f}\")\n",
        "\n",
        "# Training function for CNN model\n",
        "def train_model_cnn(model, optimizer, train_loader, model_name, epochs=1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for epoch in range(epochs):\n",
        "        for ids, targets in train_loader:\n",
        "            ids, targets = ids.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(ids)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        average_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}, {model_name} trained with average loss: {average_loss:.4f}\")\n",
        "\n",
        "# Updated evaluation function for BERT and LSTM models\n",
        "def evaluate_model(model, test_loader, model_name):\n",
        "    model.eval()\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for ids, masks, targets in test_loader:\n",
        "            ids, masks, targets = ids.to(device), masks.to(device), targets.to(device)\n",
        "            outputs = model(ids, masks)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = np.mean(np.array(all_targets) == np.array(all_predictions))\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_targets, all_predictions, average='weighted'\n",
        "    )\n",
        "\n",
        "    print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
        "    print(f\"{model_name} precision: {precision:.4f}\")\n",
        "    print(f\"{model_name} recall: {recall:.4f}\")\n",
        "    print(f\"{model_name} F1 score: {f1:.4f}\")\n",
        "\n",
        "# Updated evaluation function for CNN model\n",
        "def evaluate_model_cnn(model, test_loader, model_name):\n",
        "    model.eval()\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for ids, targets in test_loader:\n",
        "            ids, targets = ids.to(device), targets.to(device)\n",
        "            outputs = model(ids)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = np.mean(np.array(all_targets) == np.array(all_predictions))\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_targets, all_predictions, average='weighted'\n",
        "    )\n",
        "\n",
        "    print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
        "    print(f\"{model_name} precision: {precision:.4f}\")\n",
        "    print(f\"{model_name} recall: {recall:.4f}\")\n",
        "    print(f\"{model_name} F1 score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "for epoch in range(1):\n",
        "    train_model(model_bert, optimizer_bert, train_loader, \"BERT Model\", epochs=1)\n",
        "    train_model(model_lstm, optimizer_lstm, train_loader, \"LSTM Model\", epochs=1)\n",
        "    train_model_cnn(model_cnn, optimizer_cnn, train_loader_cnn, \"CNN Model\", epochs=1)\n",
        "\n",
        "    evaluate_model(model_bert, test_loader, \"BERT Model\")\n",
        "    evaluate_model(model_lstm, test_loader, \"LSTM Model\")\n",
        "    evaluate_model_cnn(model_cnn, test_loader_cnn, \"CNN Model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55x-yV8-b4i-",
        "outputId": "d98658c4-7964-4a04-a8d7-33c540376a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid categories with more than 300 occurrences:\n",
            "Index([' Surgery', ' Consult - History and Phy.',\n",
            "       ' Cardiovascular / Pulmonary', ' Orthopedic'],\n",
            "      dtype='object', name='medical_specialty')\n",
            "Epoch 1, BERT Model trained with average loss: 0.7321\n",
            "Epoch 1, LSTM Model trained with average loss: 1.2825\n",
            "Epoch 1, CNN Model trained with average loss: 1.0036\n",
            "BERT Model accuracy: 0.7296\n",
            "BERT Model precision: 0.7524\n",
            "BERT Model recall: 0.7296\n",
            "BERT Model F1 score: 0.7126\n",
            "LSTM Model accuracy: 0.4764\n",
            "LSTM Model precision: 0.2270\n",
            "LSTM Model recall: 0.4764\n",
            "LSTM Model F1 score: 0.3074\n",
            "CNN Model accuracy: 0.6824\n",
            "CNN Model precision: 0.6021\n",
            "CNN Model recall: 0.6824\n",
            "CNN Model F1 score: 0.5980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the StackingMLP model\n",
        "class ImprovedStackingMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedStackingMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(3 * len(valid_categories), 100)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(50, len(valid_categories))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Function to normalize stacking inputs with standard scaling\n",
        "def normalize_data(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    return (data - mean) / std\n",
        "\n",
        "# Ensure that all models are set to evaluation mode\n",
        "def get_model_predictions(model, data_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            if isinstance(model, BERTModel) or isinstance(model, LSTMModel):\n",
        "                ids, masks = batch[:2]\n",
        "                ids = ids.to(device)\n",
        "                masks = masks.to(device)\n",
        "                outputs = model(ids, masks)\n",
        "            elif isinstance(model, CNNModel):\n",
        "                ids = batch[0]\n",
        "                ids = ids.to(device)\n",
        "                outputs = model(ids)\n",
        "            else:\n",
        "                raise ValueError(\"Unknown model type\")\n",
        "\n",
        "            predictions.append(outputs.cpu().numpy())\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    return predictions\n",
        "\n",
        "# Generate predictions from BERT, CNN, and LSTM models\n",
        "print(\"Generating predictions from BERT model...\")\n",
        "bert_preds = get_model_predictions(model_bert, test_loader)\n",
        "print(\"Generating predictions from CNN model...\")\n",
        "cnn_preds = get_model_predictions(model_cnn, test_loader_cnn)\n",
        "print(\"Generating predictions from LSTM model...\")\n",
        "lstm_preds = get_model_predictions(model_lstm, test_loader)\n",
        "\n",
        "# Convert logits to probabilities\n",
        "bert_probs = F.softmax(torch.tensor(bert_preds), dim=1).numpy()\n",
        "cnn_probs = F.softmax(torch.tensor(cnn_preds), dim=1).numpy()\n",
        "lstm_probs = F.softmax(torch.tensor(lstm_preds), dim=1).numpy()\n",
        "\n",
        "# Prepare stacking inputs for the model\n",
        "stacking_inputs = np.concatenate([bert_probs, cnn_probs, lstm_probs], axis=1)\n",
        "stacking_inputs = normalize_data(stacking_inputs)\n",
        "\n",
        "# Convert stacking inputs to tensor and create dataset\n",
        "stacking_inputs_tensor = torch.tensor(stacking_inputs).float()\n",
        "stacking_labels_tensor = torch.tensor(y_test.numpy()).long()\n",
        "stacking_dataset = TensorDataset(stacking_inputs_tensor, stacking_labels_tensor)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "    stacking_inputs_tensor, stacking_labels_tensor, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_labels)\n",
        "test_data = TensorDataset(test_inputs, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "def train_and_evaluate_improved_stacking_model(model, optimizer, train_loader, test_loader, epochs=100, patience=50, min_delta=0.01, accuracy_threshold=0.80):\n",
        "    best_accuracy = 0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct_train_preds = 0\n",
        "        total_train_preds = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train_preds += (predicted == targets).sum().item()\n",
        "            total_train_preds += targets.size(0)\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        train_accuracy = correct_train_preds / total_train_preds\n",
        "\n",
        "        # Evaluation phase (on test data)\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct_test_preds = 0\n",
        "        total_test_preds = 0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = F.cross_entropy(outputs, targets)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_test_preds += (predicted == targets).sum().item()\n",
        "                total_test_preds += targets.size(0)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        avg_test_loss = test_loss / len(test_loader)\n",
        "        test_accuracy = correct_test_preds / total_test_preds\n",
        "\n",
        "        # Calculate F1 score, precision, and recall\n",
        "        f1 = f1_score(all_targets, all_preds, average='weighted')\n",
        "        precision = precision_score(all_targets, all_preds, average='weighted')\n",
        "        recall = recall_score(all_targets, all_preds, average='weighted')\n",
        "\n",
        "        # Print metrics for the current epoch\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
        "        print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"F1 score: {f1:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "\n",
        "        # Check for early stopping based on accuracy threshold\n",
        "        if test_accuracy > accuracy_threshold:\n",
        "            print(\"Test accuracy exceeded threshold. Stopping training.\")\n",
        "            break\n",
        "\n",
        "        # Check for early stopping based on improvement\n",
        "        if test_accuracy > best_accuracy + min_delta:\n",
        "            best_accuracy = test_accuracy\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Load the best model state\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "# Train and evaluate the improved stacking model\n",
        "improved_stacking_model = ImprovedStackingMLP().to(device)\n",
        "improved_stacking_model_optimizer = optim.Adam(improved_stacking_model.parameters(), lr=1e-2)\n",
        "train_and_evaluate_improved_stacking_model(improved_stacking_model, improved_stacking_model_optimizer, train_loader, test_loader, epochs=100, patience=25, min_delta=0.01, accuracy_threshold=0.80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjWC0vmxoGQi",
        "outputId": "6f128473-9cb6-4d91-dc1f-e578015b5c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions from BERT model...\n",
            "Generating predictions from CNN model...\n",
            "Generating predictions from LSTM model...\n",
            "Epoch 1/100\n",
            "Training loss: 1.0658, Training accuracy: 0.5933\n",
            "Test loss: 0.9712, Test accuracy: 0.6667\n",
            "F1 score: 0.5339\n",
            "Precision: 0.4456\n",
            "Recall: 0.6667\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 2/100\n",
            "Training loss: 0.7225, Training accuracy: 0.7560\n",
            "Test loss: 0.5539, Test accuracy: 0.7500\n",
            "F1 score: 0.6822\n",
            "Precision: 0.6975\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 3/100\n",
            "Training loss: 0.6681, Training accuracy: 0.7225\n",
            "Test loss: 0.5643, Test accuracy: 0.7083\n",
            "F1 score: 0.6097\n",
            "Precision: 0.5894\n",
            "Recall: 0.7083\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 4/100\n",
            "Training loss: 0.6346, Training accuracy: 0.7321\n",
            "Test loss: 0.4900, Test accuracy: 0.7083\n",
            "F1 score: 0.6097\n",
            "Precision: 0.5894\n",
            "Recall: 0.7083\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100\n",
            "Training loss: 0.5611, Training accuracy: 0.7751\n",
            "Test loss: 0.4585, Test accuracy: 0.7500\n",
            "F1 score: 0.6626\n",
            "Precision: 0.5938\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 6/100\n",
            "Training loss: 0.5462, Training accuracy: 0.7512\n",
            "Test loss: 0.5492, Test accuracy: 0.7500\n",
            "F1 score: 0.6614\n",
            "Precision: 0.6100\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 7/100\n",
            "Training loss: 0.5702, Training accuracy: 0.7751\n",
            "Test loss: 0.4721, Test accuracy: 0.7500\n",
            "F1 score: 0.6614\n",
            "Precision: 0.6100\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 8/100\n",
            "Training loss: 0.5135, Training accuracy: 0.7512\n",
            "Test loss: 0.4581, Test accuracy: 0.7500\n",
            "F1 score: 0.7221\n",
            "Precision: 0.7639\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 9/100\n",
            "Training loss: 0.5571, Training accuracy: 0.7608\n",
            "Test loss: 0.4755, Test accuracy: 0.7500\n",
            "F1 score: 0.6934\n",
            "Precision: 0.8183\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 10/100\n",
            "Training loss: 0.5101, Training accuracy: 0.7560\n",
            "Test loss: 0.4895, Test accuracy: 0.7500\n",
            "F1 score: 0.6626\n",
            "Precision: 0.5938\n",
            "Recall: 0.7500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 11/100\n",
            "Training loss: 0.5105, Training accuracy: 0.7990\n",
            "Test loss: 0.4406, Test accuracy: 0.8333\n",
            "F1 score: 0.8275\n",
            "Precision: 0.8393\n",
            "Recall: 0.8333\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Test accuracy exceeded threshold. Stopping training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "def preprocess_input(transcript):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        transcript,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    bert_probs = model_bert(input_ids, attention_mask)\n",
        "    cnn_probs = model_cnn(input_ids)\n",
        "    lstm_probs = model_lstm(input_ids, attention_mask)\n",
        "    stacking_inputs = torch.cat((bert_probs, cnn_probs, lstm_probs), dim=1)\n",
        "    return stacking_inputs"
      ],
      "metadata": {
        "id": "uAv3S0js1i93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_transcript = \"Left total knee arthroplasty performed due to severe osteoarthritis. Patient placed in supine position under general anesthesia. Tourniquet inflated. Tibial and femoral components implanted. Patellar component inserted. Wound closed in layers. Postoperative pain management initiated.\"\n",
        "preprocessed_input = preprocess_input(input_transcript)\n",
        "outputs = improved_stacking_model(preprocessed_input)\n",
        "predicted_probs = F.softmax(outputs, dim=1)\n",
        "predicted_label_idx = torch.argmax(predicted_probs, dim=1)\n",
        "labels = ['Surgery', 'Consult - History and Phy.', 'Cardiovascular / Pulmonary', 'Orthopedic']\n",
        "predicted_label = labels[predicted_label_idx.item()]"
      ],
      "metadata": {
        "id": "1UmI2ZTN1soH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhTPLAiYkKBH",
        "outputId": "8f394758-b958-4358-924a-84cccb86625f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthopedic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HwyCMgLyA3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}